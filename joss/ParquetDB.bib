@book{allenDefinitiveGuideSQLite2010,
  title = {The {{Definitive Guide}} to {{SQLite}}},
  author = {Allen, Grant and Owens, Mike},
  year = {2010},
  publisher = {Apress},
  address = {Berkeley, CA},
  doi = {10.1007/978-1-4302-3226-1},
  urldate = {2025-03-03},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-1-4302-3225-4 978-1-4302-3226-1},
  langid = {english},
  keywords = {database,database management,relational database,SQL,SQLite}
}

@article{guoMongoDBsJavaScriptFuzzer2017,
  title = {{{MongoDB}}'s {{JavaScript}} Fuzzer},
  author = {Guo, Robert},
  year = {2017},
  month = apr,
  journal = {Commun. ACM},
  volume = {60},
  number = {5},
  pages = {43--47},
  issn = {0001-0782},
  doi = {10.1145/3052937},
  urldate = {2025-03-03},
  abstract = {The fuzzer is for those edge cases that your testing did not catch.}
}

@incollection{habyarimanaGenomicsData2021,
  title = {Genomics {{Data}}},
  booktitle = {Big {{Data}} in {{Bioeconomy}}: {{Results}} from the {{European DataBio Project}}},
  author = {Habyarimana, Ephrem and Michailidou, Sofia},
  editor = {Sodergard, Caj and Mildorf, Tomas and Habyarimana, Ephrem and Berre, Arne J. and Fernandes, Jose A. and {Zinke-Wehlmann}, Christian},
  year = {2021},
  pages = {69--76},
  publisher = {Springer International Publishing},
  address = {Cham},
  urldate = {2024-10-20},
  abstract = {In silico prediction of plant performance is gaining increasing breeders' attention. Several statistical, mathematical and machine learning methodologies for analysis of phenotypic, omics and environmental data typically use individual or a few data layers. Genomic selection is one of the applications, where heterogeneous data, such as those from omics technologies, are handled, accommodating several genetic models of inheritance. There are many new high throughput Next Generation~ Sequencing (NGS) platforms on the market producing whole-genome data at a low cost. Hence, large-scale genomic data can be produced and analyzed enabling~intercrosses and ~fast-paced~recurrent selection.  The offspring properties can be~predicted instead of manually~evaluated in the~field . Breeders have a short time window to make decisions by the time they receive data,  which~is one of the major challenges in commercial breeding. To implement genomic selection routinely as part of breeding programs, data management systems and analytics capacity have therefore to be in order. The traditional relational database management systems (RDBMS), which are  designed  to store, manage and analyze large-scale data, offer appealing characteristics, particularly when they are upgraded with capabilities for working with binary large objects. In addition, NoSQL systems were considered effective tools for managing high-dimensional genomic data. MongoDB system, a document-based NoSQL database, was effectively used to develop web-based tools for visualizing and exploring genotypic information. The Hierarchical Data Format (HDF5), a member of the high-performance distributed file systems family, demonstrated superior performance with high-dimensional and highly structured data such as genomic sequencing data.},
  isbn = {978-3-030-71069-9},
  langid = {english},
  keywords = {Genomic data management,Phenomics,Phenotyping,SNPs genotyping,Whole-genome sequencing},
  annotation = {10.1007/978-3-030-71069-9\_6}
}

@article{hjorthlarsenAtomicSimulationEnvironment2017,
  title = {The Atomic Simulation Environment---a {{Python}} Library for Working with Atoms},
  author = {Hjorth Larsen, Ask and J{\o}rgen Mortensen, Jens and Blomqvist, Jakob and Castelli, Ivano E and Christensen, Rune and Du{\l}ak, Marcin and Friis, Jesper and Groves, Michael N and Hammer, Bj{\o}rk and Hargus, Cory and Hermes, Eric D and Jennings, Paul C and Bjerre Jensen, Peter and Kermode, James and Kitchin, John R and Leonhard Kolsbjerg, Esben and Kubal, Joseph and Kaasbjerg, Kristen and Lysgaard, Steen and Bergmann Maronsson, J{\'o}n and Maxson, Tristan and Olsen, Thomas and Pastewka, Lars and Peterson, Andrew and Rostgaard, Carsten and Schi{\o}tz, Jakob and Sch{\"u}tt, Ole and Strange, Mikkel and Thygesen, Kristian S and Vegge, Tejs and Vilhelmsen, Lasse and Walter, Michael and Zeng, Zhenhua and Jacobsen, Karsten W},
  year = {2017},
  month = jun,
  journal = {Journal of Physics: Condensed Matter},
  volume = {29},
  number = {27},
  pages = {273002},
  publisher = {IOP Publishing},
  issn = {0953-8984},
  doi = {10.1088/1361-648X/aa680e},
  urldate = {2025-02-28},
  abstract = {The atomic simulation environment (ASE) is a software package written in the Python programming language with the aim of setting up, steering, and analyzing atomistic simulations. In ASE, tasks are fully scripted in Python. The powerful syntax of Python combined with the NumPy array library make it possible to perform very complex simulation tasks. For example, a sequence of calculations may be performed with the use of a simple `for-loop' construction. Calculations of energy, forces, stresses and other quantities are performed through interfaces to many external electronic structure codes or force fields using a uniform interface. On top of this calculator interface, ASE provides modules for performing many standard simulation tasks such as structure optimization, molecular dynamics, handling of constraints and performing nudged elastic band calculations.},
  langid = {english}
}

@article{jainCommentaryMaterialsProject2013,
  title = {Commentary: {{The Materials Project}}: {{A}} Materials Genome Approach to Accelerating Materials Innovation},
  shorttitle = {Commentary},
  author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, Geoffroy and Chen, Wei and Richards, William Davidson and Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and Skinner, David and Ceder, Gerbrand and Persson, Kristin A.},
  year = {2013},
  month = jul,
  journal = {APL Materials},
  volume = {1},
  number = {1},
  pages = {011002},
  issn = {2166-532X},
  doi = {10.1063/1.4812323},
  urldate = {2024-10-20},
  abstract = {Accelerating the discovery of advanced materials is essential for human welfare and sustainable, clean energy. In this paper, we introduce the Materials Project (www.materialsproject.org), a core program of the Materials Genome Initiative that uses high-throughput computing to uncover the properties of all known inorganic materials. This open dataset can be accessed through multiple channels for both interactive exploration and data mining. The Materials Project also seeks to create open-source platforms for developing robust, sophisticated materials analyses. Future efforts will enable users to perform ``rapid-prototyping'' of new materials in silico, and provide researchers with new avenues for cost-effective, data-driven materials design.}
}

@book{pascalPracticalIssuesDatabase2000,
  title = {Practical {{Issues}} in {{Database Management}}: {{A Refernce}} for the {{Thinking Practitioner}}},
  shorttitle = {Practical {{Issues}} in {{Database Management}}},
  author = {Pascal, Fabian},
  year = {2000},
  month = jan,
  edition = {1st edition},
  publisher = {Addison-Wesley Professional},
  address = {Boston, Mass},
  abstract = {Databas(e)ics clearly explains the key concepts users and database professionals need to understand in order to build well-designed databases that answer business questions accurately and efficiently. Fabian Pascal, one of the industry's leading experts, identifies ten critical, recurring issues that both database users and vendors often fail to address appropriately. Pascal demonstrates why understanding these fundamentals is so important, providing detailed examples and solutions designed to help users escape the key pitfalls of database development.KEY TOPICS:Among the topics covered: unstructured data and complex data types; business rules and enforcing data integrity; keys; duplicates; normalization; entity subtypes and supertypes; data hierarchies and recursive queries; redundancy; quota queries; and how to handle missing information. Along the way, Pascal offers no-holds-barred assessments of how well current SQL implementations and commercial products address each issue. Databas(e)ics, in short, is a complete guide to building databases right the first time, so they don't have to be rebuilt later.MARKET:For all DBAs, developers, managers, and end-users that need to understand the best ways to design and implement database systems. Databasics clearly explains the key concepts users and database professionals need to understand in order to build well-designed databases that answer business questions accurately and efficiently. Fabian Pascal, one of the industry's leading experts, identifies ten critical, recurring issues that both database users and vendors often fail to address appropriately. Pascal demonstrates why understanding these fundamentals is so important, providing detailed examples and solutions designed to help users escape the key pitfalls of database development. Among the topics covered: unstructured data and complex data types; business rules and enforcing data integrity; keys; duplicates; normalization; entity subtypes and supertypes; data hierarchies and recursive queries; redundancy; quota queries; and how to handle missing information. Along the way, Pascal offers no-holds-barred assessments of how well current SQL implementations and commercial products address each issue. Databasics, in short, is a complete guide to building databases right the first time, so they don't have to be rebuilt later. For all DBAs, developers, managers, and end-users that need to understand the best ways to design and implement database systems.},
  isbn = {978-0-201-48555-4},
  langid = {english}
}

@book{pivertNoSQLDataModels2018,
  title = {{{NoSQL Data Models}}: {{Trends}} and {{Challenges}}},
  shorttitle = {{{NoSQL Data Models}}},
  editor = {Pivert, Olivier},
  year = {2018},
  month = aug,
  edition = {1st edition},
  publisher = {Wiley-ISTE},
  address = {London, UK},
  abstract = {The topic of NoSQL databases has recently emerged, to face the Big Data challenge, namely the ever increasing volume of data to be handled. It is now recognized that relational databases are not appropriate in this context, implying that new database models and techniques are needed. This book presents recent research works, covering the following basic aspects: semantic data management, graph databases, and big data management in cloud environments. The chapters in this book report on research about the evolution of basic concepts such as data models, query languages, and new challenges regarding implementation issues.},
  isbn = {978-1-78630-364-6},
  langid = {english}
}


@misc{Parquet,
  title = {Parquet},
  journal = {Apache Parquet},
  urldate = {2024-10-21},
  abstract = {The Apache Parquet Website},
  howpublished = {https://parquet.apache.org/},
  langid = {english}
}


@misc{WelcomeApacheSoftware,
  title = {Welcome to {{The Apache Software Foundation}}},
  urldate = {2025-04-28},
  howpublished = {https://www.apache.org/}
}


@misc{HDF5PythonH5py,
  title = {{{HDF5}} for {{Python}} --- H5py 3.13.0 Documentation},
  urldate = {2025-04-28},
  howpublished = {https://docs.h5py.org/en/stable/index.html}
}

@misc{langParquetDBLightweightPython2025,
  title = {{{ParquetDB}}: {{A Lightweight Python Parquet-Based Database}}},
  shorttitle = {{{ParquetDB}}},
  author = {Lang, Logan and Hernandez, Eduardo and Choudhary, Kamal and Romero, Aldo H.},
  year = {2025},
  month = feb,
  number = {arXiv:2502.05311},
  eprint = {2502.05311},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.05311},
  urldate = {2025-02-14},
  abstract = {Traditional data storage formats and databases often introduce complexities and inefficiencies that hinder rapid iteration and adaptability. To address these challenges, we introduce ParquetDB, a Python-based database framework that leverages the Parquet file format's optimized columnar storage. ParquetDB offers efficient serialization and deserialization, native support for complex and nested data types, reduced dependency on indexing through predicate pushdown filtering, and enhanced portability due to its file-based storage system. Benchmarks show that ParquetDB outperforms traditional databases like SQLite and MongoDB in managing large volumes of data, especially when using data formats compatible with PyArrow. We validate ParquetDB's practical utility by applying it to the Alexandria 3D Materials Database, efficiently handling approximately 4.8 million complex and nested records. By addressing the inherent limitations of existing data storage systems and continuously evolving to meet future demands, ParquetDB has the potential to significantly streamline data management processes and accelerate research development in data-driven fields.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases,Physics - Data Analysis Statistics and Probability}
}
